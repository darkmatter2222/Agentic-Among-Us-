# LLM Server SSH Configuration
# Copy this file to .env and fill in your credentials

# SSH Connection
SSH_HOST=192.168.86.48
SSH_USER=your_username
SSH_KEY_PATH=~/.ssh/id_rsa
# Or use password instead of key (less secure)
# SSH_PASSWORD=your_password

# Docker Configuration
CONTAINER_NAME=llama-cpp-server
GPU_ID=0

# Model Configuration
# Qwen3-8B-GGUF Q8_0 quantization - recommended for RTX 3090
MODEL_REPO=Qwen/Qwen3-8B-GGUF
MODEL_FILE=qwen3-8b-q8_0.gguf
MODEL_PATH=/models

# llama.cpp Server Settings
LLAMA_PORT=8080
CONTEXT_SIZE=32768
GPU_LAYERS=99
THREADS=8
