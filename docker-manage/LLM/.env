# LLM Server SSH Configuration
# Copy this file to .env and fill in your credentials

# SSH Connection
SSH_HOST=192.168.86.48
SSH_USER=darkmatter2222
SSH_KEY_PATH=~/.ssh/id_rsa
# Or use password instead of key (less secure)
SSH_PASSWORD=B10hazard!

# Docker Configuration
CONTAINER_NAME=llama-cpp-server
GPU_ID=0

# Model Configuration
# Llama-3.2-1B-Instruct Q5_K_M - Strong reasoning, fast (~60-150 tok/s on 3090)
MODEL_REPO=bartowski/Llama-3.2-1B-Instruct-GGUF
MODEL_FILE=Llama-3.2-1B-Instruct-Q5_K_M.gguf
MODEL_PATH=/models

# llama.cpp Server Settings
LLAMA_PORT=8080
CONTEXT_SIZE=4096
GPU_LAYERS=99
THREADS=8
FLASH_ATTENTION=true