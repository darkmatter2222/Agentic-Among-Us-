# Fine-tuning requirements for Llama 3.2 1B
# Tested with RTX 5090 + PyTorch

torch>=2.1.0
transformers>=4.36.0
datasets>=2.14.0
accelerate>=0.25.0
peft>=0.7.0
bitsandbytes>=0.41.0
trl>=0.7.0
wandb>=0.16.0
scipy>=1.11.0
sentencepiece>=0.1.99
protobuf>=3.20.0
huggingface_hub>=0.19.0
matplotlib>=3.8.0  # For benchmark visualizations
# flash-attn>=2.5.0  # Optional - requires CUDA build tools on Windows
